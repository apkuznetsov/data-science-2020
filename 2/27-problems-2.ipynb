{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одно дерево - хорошо, но где гарантии, что оно является лучшим, или хотя бы близко к нему? Одним из способов найти более-менее оптимальный набор параметров дерева является перебор множества деревьев с разными параметрами и выбор подходящего.\n",
    "\n",
    "Для этой цели существует класс GridSearchCV, перебирающий каждое из сочетаний параметров среди заданных для модели, обучающий её на данных и проводящих кросс-валидацию. После этого в аттрибуте .best_estimator_ храниться модель с лучшими параметрами.\n",
    "Это применимо не только к деревьям, но и к другим моделям sklearn.\n",
    "\n",
    "Теперь задание - осуществите перебор всех деревьев на данных ириса по следующим параметрам:\n",
    "* максимальная глубина - от 1 до 10 уровней\n",
    "* минимальное число проб для разделения - от 2 до 10\n",
    "* минимальное число проб в листе - от 1 до 10\n",
    "\n",
    "и сохраните в переменную best_tree лучшее дерево. Переменную с GridSearchCV назовите search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "parametrs = {'criterion': ['entropy'],\n",
    "             'max_depth': range(1,10),\n",
    "             'min_samples_split': range(2,10),\n",
    "             'min_samples_leaf': range(1,10)}\n",
    "search = GridSearchCV(dt, parametrs, cv=5)\n",
    "\n",
    "search.fit(X,y)\n",
    "best_tree = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем больше данных, сложность модели и число её параметров, тем дольше будет вестись поиск GridSearchCV. Однако бывают случаи, когда модель нужна здесь и сейчас, и для этого есть RandomizedSearchCV! Пробегаясь по рандомной подвыборке параметров, он ищет наиболее хорошую модель и делает это быстрее полного перебора параметров, хотя и может пропустить оптимальные параметры.\n",
    "\n",
    "Здесь можно посмотреть на сравнение этих поисков.\n",
    "\n",
    "Осуществим поиск по тем же параметрам что и в предыдущем задании с помощью RandomizedSearchCV\n",
    "\n",
    "максимальная глубина - от 1 до 10 уровней\n",
    "минимальное число проб для разделения - от 2 до 10\n",
    "минимальное число проб в листе - от 1 до 10\n",
    "Cохраните в переменную best_tree лучшее дерево. Переменную с RandomizedSearchCV назовите search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "search = RandomizedSearchCV(dt, parametrs, cv=5)\n",
    "\n",
    "search.fit(X,y)\n",
    "best_tree = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся изученными приёмами и попредсказываем!\n",
    "\n",
    "Даны 2 датасэта, к которым вы можете обращаться:\n",
    "\n",
    "    train - размеченный с известными правильным ответами (хранятся в колонке y)\n",
    "    test - набор, где нужно предсказать их\n",
    "Найдите дерево с наиболее подходящими параметрами с помощью GridSearchCV и предскажите с его помощью ответы ко 2-ому сэту! Границы параметров как раньше:\n",
    "\n",
    "максимальная глубина - от 1 до 10 уровней\n",
    "минимальное число проб для разделения - от 2 до 10\n",
    "минимальное число проб в листе - от 1 до 10\n",
    "Названия переменных тоже:лучшее дерево - best_tree, GridSearchCV - search, а предсказания - predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "parametrs = {'max_depth': range(1,10),\n",
    "             'min_samples_split': range(2,10),\n",
    "             'min_samples_leaf': range(1,10)}\n",
    "search = GridSearchCV(dt, parametrs, cv=5)\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "best_tree = search.best_estimator_\n",
    "\n",
    "predictions = best_tree.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При классификации модель может допускать ошибки, присваивая наблюдению неверный класс. Существуют различные метрики оценки качества предсказаний, которые базируются на 4-ёх параметрах - true positive, false positive, false negative и true negative, соответствующих тому какой класс был присвоен наблюдениям каждого из классов. Матрицу из 4-ёх (в случае бинарной классификации) этих параметров называют confusion matrix.\n",
    "\n",
    "В sklearn можно её удобно получить с помощью функции confusion_matrix. Вам даны 2 эррея с истинными классами наблюдений и предсказанными - y и predictions. Получите по ним confusion matrix и поместите её в переменную conf_matrix.\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y, predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
